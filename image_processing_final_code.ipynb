{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarnim-sawane/hackout/blob/main/image_processing_final_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNoYf8cdxuPh",
        "outputId": "d00f4fb4-30ff-4aea-faa1-2e286c4d16fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (4,920 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-ocr opencv-python numpy matplotlib pdf2image python-docx pytesseract PyMuPDF gTTS torch replicate gTTS PromptCap transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-YX0Azch7wM",
        "outputId": "3b31eaa6-0c42-410c-fed5-c0a45109932c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-ocr in /usr/local/lib/python3.10/dist-packages (0.8.9)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.23.4)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: replicate in /usr/local/lib/python3.10/dist-packages (0.15.4)\n",
            "Requirement already satisfied: PromptCap in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.6.2)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (1.0.0)\n",
            "Requirement already satisfied: essential_generators in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (1.0)\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.43.1)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.4.0)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (1.3.0.post5)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (4.66.1)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.10/dist-packages (from keras-ocr) (0.22.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr) (0.19.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.3 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.23.3)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.2)\n",
            "Requirement already satisfied: pydantic>1 in /usr/local/lib/python3.10/dist-packages (from replicate) (1.10.13)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (0.25.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (0.18.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (1.11.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr) (2.31.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.4.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx<1,>=0.21.0->replicate) (1.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5mlRvQ_h1O3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pdf2image import convert_from_path\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_ocr\n",
        "import math\n",
        "import fitz\n",
        "import os\n",
        "import docx\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from promptcap import PromptCap\n",
        "import torch\n",
        "from gtts import gTTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_pdf_path = \"/content/test.pdf\"\n",
        "output_image_folder = \"output_images\"\n",
        "\n",
        "output_image_folder = \"/content/output_images\"\n",
        "output_text_removed_folder = \"text_removed_images\"\n",
        "output_text_extracted_folder = \"extracted_text\"\n",
        "text_removed_folder = \"/content/text_removed_images\"\n",
        "\n",
        "original_image_folder = \"/content/output_images\"\n",
        "processed_image_folder = \"/content/text_removed_images\"\n",
        "output_folder = \"final_images\"\n",
        "\n",
        "os.makedirs(output_image_folder, exist_ok=True)\n",
        "os.makedirs(output_text_removed_folder, exist_ok=True)\n",
        "os.makedirs(output_text_extracted_folder, exist_ok=True)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "docx_folder_path = \"/content/extracted_text\"\n",
        "image_folder_root = \"/content\"\n",
        "\n",
        "context_dict = []\n",
        "index_const = 0"
      ],
      "metadata": {
        "id": "GzoX92bPGY_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF to Image"
      ],
      "metadata": {
        "id": "bW-6Qh0oKFcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def pdf_to_images(pdf_path, image_folder):\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "    for page_number in range(len(pdf_document)):\n",
        "        page = pdf_document[page_number]\n",
        "        image = page.get_pixmap()\n",
        "        image_path = f\"{image_folder}/page_{page_number + 1}.png\"\n",
        "        image.save(image_path, \"PNG\")\n",
        "    pdf_document.close()\n"
      ],
      "metadata": {
        "id": "x9RBsfyVkqgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction followed by removal of text"
      ],
      "metadata": {
        "id": "d5nmYWgaKQlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def midpoint(x1, y1, x2, y2):\n",
        "    x_mid = int((x1 + x2)/2)\n",
        "    y_mid = int((y1 + y2)/2)\n",
        "    return (x_mid, y_mid)\n",
        "\n",
        "\n",
        "def inpaint_text(img_path, pipeline,page_number):\n",
        "    img = keras_ocr.tools.read(img_path)\n",
        "    prediction_groups = pipeline.recognize([img])\n",
        "    extracted_text = []\n",
        "    mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
        "    for box in prediction_groups[0]:\n",
        "        x0, y0 = box[1][0]\n",
        "        x1, y1 = box[1][1]\n",
        "        x2, y2 = box[1][2]\n",
        "        x3, y3 = box[1][3]\n",
        "\n",
        "        x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
        "        x_mid1, y_mi1 = midpoint(x0, y0, x3, y3)\n",
        "\n",
        "        thickness = int(math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 ))\n",
        "\n",
        "        cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mi1), 255,\n",
        "        thickness)\n",
        "        inpainted_img = cv2.inpaint(img, mask, 7, cv2.INPAINT_NS)\n",
        "\n",
        "        text = box[0]\n",
        "        extracted_text.append(text)\n",
        "\n",
        "    combined_text = ' '.join(extracted_text)\n",
        "    dox_output_path = f\"{output_text_extracted_folder}/page_{page_number + 1}_text.docx\"\n",
        "\n",
        "    doc = docx.Document()\n",
        "    doc.add_paragraph(combined_text)\n",
        "    doc.save(dox_output_path)\n",
        "\n",
        "\n",
        "    return(inpainted_img)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lJ0C8A8v37bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dd-Dctkdz2c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image extraction"
      ],
      "metadata": {
        "id": "UEb_DmtVKZo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def detect_images_in_page(page, page_number):\n",
        "    img = cv2.imread(page)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    min_area = 1000\n",
        "    detected_images = []\n",
        "\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) > min_area:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            detected_images.append(img[y:y+h, x:x+w])\n",
        "\n",
        "            output_folder = f\"detected_images_page_{page_number + 1}\"\n",
        "            os.makedirs(output_folder, exist_ok=True)\n",
        "            output_path = os.path.join(output_folder, f\"image_{i + 1}.jpg\")\n",
        "            cv2.imwrite(output_path, detected_images)\n",
        "\n",
        "    return detected_images"
      ],
      "metadata": {
        "id": "SSw_C28_C1C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cyefheINO1Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labelling the image"
      ],
      "metadata": {
        "id": "kCSuNq7GKksy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "padding = 40\n",
        "\n",
        "def process_images(original_image_path, processed_image_path):\n",
        "\n",
        "    original_image = cv2.imread(original_image_path)\n",
        "    height, width, _ = original_image.shape\n",
        "    processed_image = cv2.imread(processed_image_path)\n",
        "    processed_image = cv2.resize(processed_image, (width, height))\n",
        "    gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    min_area_threshold = 900\n",
        "\n",
        "    white_fill = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
        "\n",
        "    for idx, contour in enumerate(contours):\n",
        "        area = cv2.contourArea(contour)\n",
        "\n",
        "        if area > min_area_threshold:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            center_x = x + w // 2\n",
        "            center_y = y + h // 2\n",
        "\n",
        "            text = \"context_dict[idx]\"\n",
        "            # index_const+=1\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_scale = 0.5\n",
        "            font_color = (0, 0, 0)\n",
        "            font_thickness = 1\n",
        "            text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
        "\n",
        "            text_x = center_x - text_size[0] // 2\n",
        "            text_y = center_y + text_size[1] // 2\n",
        "\n",
        "            box_x1 = text_x - padding\n",
        "            box_y1 = text_y - text_size[1] - padding\n",
        "            box_x2 = text_x + text_size[0] + padding\n",
        "            box_y2 = text_y + padding\n",
        "            cv2.rectangle(processed_image, (box_x1, box_y1), (box_x2, box_y2), (255, 255, 255), -1)\n",
        "\n",
        "            cv2.putText(processed_image, text, (text_x, text_y), font, font_scale, font_color, font_thickness)\n",
        "\n",
        "\n",
        "    return processed_image\n",
        "\n"
      ],
      "metadata": {
        "id": "vDFwFNyDVpFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Caption for Image"
      ],
      "metadata": {
        "id": "NX2hCDGSKrRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(context,image):\n",
        "    model = PromptCap(\"vqascore/promptcap-coco-vqa\")  # also support OFA checkpoints. e.g. \"OFA-Sys/ofa-large\"\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "\n",
        "    prompt = \"please describe this image according to the given context:\" + context\n",
        "\n",
        "    x = model.caption(prompt, image)\n",
        "\n",
        "    context_dict.append(x)"
      ],
      "metadata": {
        "id": "4Zmpn0v7nXuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Aloud"
      ],
      "metadata": {
        "id": "R2WZgl1ELBnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tts(text,language):\n",
        "  text = text\n",
        "  tts = gTTS(text, lang=language)\n",
        "  tts.save(\"output.mp3\")\n",
        "  os.system(\"start output.mp3\")\n",
        "\n",
        "def ocr(img):\n",
        "  filename = img\n",
        "  img = cv2.imread(filename)\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  text = pytesseract.image_to_string(Image.fromarray(img_rgb))\n",
        "  text = ' '.join(text)\n",
        "  return text\n",
        "\n",
        "def read_aloud(language):\n",
        "  for page_number in range(len(os.listdir(output_image_folder))):\n",
        "        page_image_path = f\"final_images/page_{page_number + 1}.png\"\n",
        "        text_extracted = ocr(page_image_path)\n",
        "        tts(text_extracted,language)\n"
      ],
      "metadata": {
        "id": "_whFkLordnEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Program"
      ],
      "metadata": {
        "id": "R-SrurKPnlJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    pipeline = keras_ocr.pipeline.Pipeline()\n",
        "\n",
        "    ### pdf to image ###\n",
        "    extracted_images = pdf_to_images(input_pdf_path, output_image_folder)\n",
        "\n",
        "    ### text extraction and removal ###\n",
        "\n",
        "    for page_number in range(len(os.listdir(output_image_folder))):\n",
        "        page_image_path = f\"{output_image_folder}/page_{page_number + 1}.png\"\n",
        "        img_text_removed = inpaint_text(page_image_path, pipeline,page_number)\n",
        "        output_path = f\"{output_text_removed_folder}/page_{page_number + 1}_text_removed.jpg\"\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(img_text_removed, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    ### image extraction ###\n",
        "    i = 0\n",
        "    n = len(sorted(os.listdir(text_removed_folder)))\n",
        "\n",
        "    for page_number, page_image_path in enumerate(sorted(os.listdir(text_removed_folder))):\n",
        "        if i<n-1 :\n",
        "          i+=1\n",
        "        else:\n",
        "          break\n",
        "        page_image = f\"{text_removed_folder}/page_{page_number + 1}_text_removed.jpg\"\n",
        "        detected_images = detect_images_in_page(page_image, page_number)\n",
        "\n",
        "\n",
        "    ### context generation and enhancement ###\n",
        "    for page_number, doc_path in enumerate(sorted(os.listdir(docx_folder_path))):\n",
        "      if doc_path.endswith(\".docx\"):\n",
        "          docx_file_path = os.path.join(docx_folder_path, doc_path)\n",
        "\n",
        "          doc = docx.Document(docx_file_path)\n",
        "\n",
        "          text = \"\"\n",
        "          for paragraph in doc.paragraphs:\n",
        "              text += paragraph.text + \"\\n\"\n",
        "\n",
        "          image_folder = os.path.join(image_folder_root, f\"detected_images_page_{page_number + 1}\")\n",
        "          if os.path.exists(image_folder):\n",
        "              image_files = [f for f in os.listdir(image_folder) if f.endswith(\".jpg\")]\n",
        "              if image_files:\n",
        "                  image_path = os.path.join(image_folder, image_files[0])\n",
        "                  img = cv2.imread(image_path)\n",
        "                  generate_text(text,img)\n",
        "\n",
        "\n",
        "    ### image labelling ###\n",
        "\n",
        "    original_image_files = sorted(os.listdir(original_image_folder))\n",
        "    processed_image_files = [f for f in os.listdir(text_removed_folder) if f.endswith('.jpg')]\n",
        "\n",
        "    i = 0\n",
        "    n = len(sorted(os.listdir(original_image_folder)))\n",
        "    for page_number, (original_image_file, processed_image_file) in enumerate(zip(original_image_files, processed_image_files)):\n",
        "\n",
        "        original_image_path = os.path.join(original_image_folder, original_image_file)\n",
        "        processed_image_path = os.path.join(processed_image_folder, processed_image_file)\n",
        "\n",
        "        output_image = process_images(processed_image_path,original_image_path)\n",
        "        output_image_file_path = f\"{output_folder}/page_{page_number + 1}_with_contours.jpg\"\n",
        "        cv2.imwrite(output_image_file_path, cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7U4AcPanl2f",
        "outputId": "8f90c57a-8a4a-4a99-8489-6ddec694378f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Looking for /root/.keras-ocr/crnn_kurapan.h5\n",
            "1/1 [==============================] - 39s 39s/step\n",
            "9/9 [==============================] - 68s 7s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(context_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKT77XDxTQlV",
        "outputId": "a064851b-ef6c-4975-df2a-ad63ff8df554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7-KUVkmHrIZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FPg4snXKrGki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6RQFIJw9NbK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}